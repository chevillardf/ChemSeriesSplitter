{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from rdkit import Chem, DataStructs, RDLogger\n",
    "from rdkit.Chem import rdChemReactions, AllChem, Draw, PandasTools\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bb_smi_label(smi):\n",
    "    return re.sub(r\"\\[\\d{2}\\*\\]\", \"[*]\", smi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/DORA_Lactam_mols_bbs.json\", \"r\") as f:\n",
    "    mols = json.load(f)\n",
    "with open(\"../data/raw/DORA_Lactam_bbs.json\", \"r\") as f:\n",
    "    bbs = json.load(f)\n",
    "    \n",
    "df_mols = pd.json_normalize(mols)\n",
    "df_bbs = pd.json_normalize(bbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform (cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbs = df_bbs[[\"bb_smi\", \"bb_id\"]]\n",
    "df_mols = df_mols[[\"mol_smi\", \"mol_id\", \"A_id\", \"B_id\", \"C_id\"]]\n",
    "\n",
    "for col in [\"A\", \"B\", \"C\"]:\n",
    "    df_mols = df_mols.merge(\n",
    "        df_bbs,\n",
    "        left_on=f\"{col}_id\",\n",
    "        right_on=\"bb_id\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"bb_smi\": f\"{col}_smi\"}).drop(columns=[\"bb_id\"])\n",
    "\n",
    "df_mols = df_mols.dropna(subset=[\"A_id\", \"B_id\", \"C_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"A_smi\", \"B_smi\", \"C_smi\"]:\n",
    "    df_mols[col] = df_mols[col].apply(remove_bb_smi_label)\n",
    "    \n",
    "df_mols['bbs_smi'] = df_mols['A_smi'] + '.' + df_mols['B_smi'] + '.' + df_mols['C_smi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_mols.sample(n=25, random_state=42)  \n",
    "df_trainval = df_mols.drop(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval.to_pickle(\"../data/staging/trainval_dataset.pkl\")\n",
    "df_test.to_pickle(\"../data/transformed/test_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mols[['mol_smi','bbs_smi']].to_csv(\"../data/staging/trainval_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import random\n",
    "\n",
    "def augment_smiles(smiles, num_aug=10):\n",
    "    \"\"\"\n",
    "    Generate augmented SMILES strings for the same molecule.\n",
    "    \n",
    "    Args:\n",
    "        smiles (str): input SMILES\n",
    "        num_aug (int): number of augmented SMILES to generate\n",
    "    \n",
    "    Returns:\n",
    "        list of str: augmented SMILES (non-canonical)\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return []\n",
    "    \n",
    "    aug_smiles = set()\n",
    "    for _ in range(num_aug):\n",
    "        # Use random atom ordering to generate non-canonical SMILES\n",
    "        aug = Chem.MolToSmiles(mol, doRandom=True)\n",
    "        aug_smiles.add(aug)\n",
    "    \n",
    "    return list(aug_smiles)\n",
    "    \n",
    "def augment_dataset(df, smiles_cols, n_aug=10):\n",
    "    \"\"\"\n",
    "    Augment a dataset by randomizing SMILES in selected columns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    smiles_cols : list of str\n",
    "        Column names that contain SMILES to augment.\n",
    "    n_aug : int\n",
    "        Number of augmented versions per row (excluding original).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Augmented dataframe with (n_aug+1) rows per original row.\n",
    "    \"\"\"\n",
    "    augmented_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # keep the original row\n",
    "        augmented_rows.append(row.to_dict())\n",
    "        \n",
    "        # generate augmented rows\n",
    "        for i in range(n_aug):\n",
    "            new_row = row.to_dict()\n",
    "            for col in smiles_cols:\n",
    "                smi = row[col]\n",
    "                aug_list = augment_smiles(smi, num_aug=10)\n",
    "                new_row[col] = aug_list[0]\n",
    "            augmented_rows.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(augmented_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = augment_dataset(df_trainval, smiles_cols=[\"mol_smi\", \"A_smi\", \"B_smi\", \"C_smi\"], n_aug=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug.to_pickle(\"../data/transformed/trainval_dataset_augmented.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.read_pickle(\"../data/transformed/trainval_dataset_augmented.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform (encode/decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokens\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "special_tokens = [\"<pad>\", \"<s>\", \"</s>\"]\n",
    "all_smiles = df_aug['mol_smi'].tolist() + df_aug['bbs_smi'].tolist()\n",
    "chars = set(\"\".join(all_smiles))\n",
    "itos = special_tokens + sorted(list(chars))   # index-to-string\n",
    "stoi = {ch: i for i, ch in enumerate(itos)}   # string-to-index\n",
    "pad_id = stoi[\"<pad>\"]\n",
    "\n",
    "with open(\"../tokens/stoi.pkl\", \"wb\") as f:\n",
    "    pickle.dump(stoi, f)\n",
    "with open(\"../tokens/itos.pkl\", \"wb\") as f:\n",
    "    pickle.dump(itos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../tokens/stoi.pkl\", \"rb\") as f:\n",
    "    stoi = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(smiles, stoi, max_len=128):\n",
    "    # returns list of token IDs with <s> at start, </s> at end, padded\n",
    "    ids = [stoi[\"<s>\"]] + [stoi[ch] for ch in smiles] + [stoi[\"</s>\"]]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [stoi[\"<pad>\"]] * (max_len - len(ids))\n",
    "    return ids[:max_len]\n",
    "\n",
    "def decode(ids, itos):\n",
    "    # returns string ignoring special tokens\n",
    "    chars = [itos[i] for i in ids if itos[i] not in (\"<pad>\", \"<s>\", \"</s>\")]\n",
    "    return \"\".join(chars)\n",
    "\n",
    "def encode_target(smi, stoi, max_len=128):\n",
    "    full_ids = encode(smi, stoi, max_len)   # <s> ... </s> + pad\n",
    "    tgt_in = full_ids[:-1]                  # decoder input (drop final </s>)\n",
    "    tgt_out = full_ids[1:]                  # loss target (drop initial <s>)\n",
    "    return tgt_in, tgt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode df\n",
    "df_aug['tgt_in'], df_aug['tgt_out'] = zip(*df_aug['bbs_smi'].apply(lambda x: encode_target(x, stoi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug.to_parquet(\"../data/transformed/trainval_dataset_augmented_encoded.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
